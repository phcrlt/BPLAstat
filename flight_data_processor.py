# flight_data_processor.py

import pandas as pd
import re
import time
import json
import logging
from datetime import datetime, timedelta
from sqlalchemy import create_engine, text
import sys
import os
import glob
import geopandas as gpd
from shapely.geometry import Point
from metrics_calculator import calculate_metrics

from config import DB_URL, UPLOADS_FOLDER

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# === üóÉ –°–¢–†–£–ö–¢–£–†–ê –¢–ê–ë–õ–ò–¶–´ ===
DESIRED_COLUMNS = {
    "id": "SERIAL PRIMARY KEY",
    "flight_id": "TEXT",
    "dof": "DATE",
    "opr": "TEXT",
    "reg": "TEXT",
    "typ": "TEXT",
    "typ_desc": "TEXT",
    "sid": "TEXT",
    "source_file": "TEXT",
    "takeoff_time": "TEXT",
    "landing_time": "TEXT",
    "takeoff_coords": "TEXT",
    "landing_coords": "TEXT",
    "takeoff_region_id": "INTEGER",
    "flight_duration_minutes": "INTEGER",
    "created_at": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP"
}

TABLE_NAME = "flights"
REGIONS_TABLE = "russia_regions"

# === üìö –†–ê–°–®–ò–§–†–û–í–ö–ê –¢–ò–ü–û–í ===
TYP_DESCRIPTIONS = {
    "BLA": "–±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π –ª–µ—Ç–∞—Ç–µ–ª—å–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç",
    "AER": "–ø–∏–ª–æ—Ç–∏—Ä—É–µ–º—ã–π –∞—ç—Ä–æ—Å—Ç–∞—Ç",
    "SHAR": "—à–∞—Ä-–∑–æ–Ω–¥ (–ø—Ä–∏–≤—è–∑–Ω–æ–π –∞—ç—Ä–æ—Å—Ç–∞—Ç, –ø–∞—Ä–∞–ø–ª–∞–Ω –∏ —Ç.–¥.)"
}

def find_geojson_file():
    """–ù–∞—Ö–æ–¥–∏—Ç GeoJSON —Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ uploads"""
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É uploads –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(UPLOADS_FOLDER, exist_ok=True)
        
        # –ü—É—Ç—å –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–∞–π–ª—É
        default_geojson = os.path.join(UPLOADS_FOLDER, "russia_regions.geojson")
        
        if os.path.exists(default_geojson):
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω GeoJSON —Ñ–∞–π–ª: {default_geojson}")
            return default_geojson
        
        # –ï—Å–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –∏—â–µ–º –ª—é–±–æ–π .geojson —Ñ–∞–π–ª
        geojson_files = glob.glob(os.path.join(UPLOADS_FOLDER, "*.geojson"))
        
        if geojson_files:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            geojson_file = geojson_files[0]
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω GeoJSON —Ñ–∞–π–ª: {geojson_file}")
            return geojson_file
        else:
            logger.error(f"‚ùå –í –ø–∞–ø–∫–µ {UPLOADS_FOLDER} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ GeoJSON —Ñ–∞–π–ª–æ–≤")
            return None
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ GeoJSON —Ñ–∞–π–ª–∞: {e}")
        return None

# === üîß –§–£–ù–ö–¶–ò–ò –ü–ê–†–°–ò–ù–ì–ê ===

def is_valid_coords(coord_str):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (11 –∏–ª–∏ 15 —Å–∏–º–≤–æ–ª–æ–≤)"""
    if not coord_str or pd.isna(coord_str):
        return False
    
    coord_str = str(coord_str).strip().replace(" ", "").upper()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
    if len(coord_str) not in [11, 15]:
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π N/S –∏ E/W
    has_ns = 'N' in coord_str or 'S' in coord_str
    has_ew = 'E' in coord_str or 'W' in coord_str
    
    if not (has_ns and has_ew):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–∏—Ñ—Ä—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏—è—Ö
    try:
        if len(coord_str) == 11:
            # –§–æ—Ä–º–∞—Ç DDMMNDDDMME
            int(coord_str[0:4])
            if coord_str[4] not in ['N', 'S']:
                return False
            int(coord_str[5:9])
            if coord_str[10] not in ['E', 'W']:
                return False
        else:  # 15 —Å–∏–º–≤–æ–ª–æ–≤
            # –§–æ—Ä–º–∞—Ç DDMMSSNDDDMMSSE
            int(coord_str[0:6])
            if coord_str[6] not in ['N', 'S']:
                return False
            int(coord_str[7:13])
            if coord_str[14] not in ['E', 'W']:
                return False
    except (ValueError, IndexError):
        return False
    
    return True

def get_best_coords(*coord_sources):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    for coords in coord_sources:
        if is_valid_coords(coords):
            return coords
    return None

def shr_pars(message):
    """–ü–∞—Ä—Å–∏–Ω–≥ SHR —Å–æ–æ–±—â–µ–Ω–∏–π"""
    shr = {}
    if not message or len(str(message).strip()) == 0:
        return shr
    try:
        text = str(message).strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º flight_id –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ (SHR-XXXXX)
        if text.startswith("(SHR-"):
            flight_part = text[5:].split('\n', 1)[0].split()[0]
            shr["flight_id"] = flight_part[:5]
        else:
            shr["flight_id"] = ""

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ —É–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (SHR-...)
        lines = text.splitlines()
        content_lines = []
        for line in lines[1:]:
            stripped = line.strip()
            if stripped.startswith('-'):
                content_lines.append(stripped[1:].strip())
            elif content_lines:
                content_lines[-1] += " " + stripped

        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –±–ª–æ–∫ —Ç–µ–≥–æ–≤
        service_lines = []
        tag_block_parts = []
        in_tag_block = False

        for line in content_lines:
            if not line:
                continue
            if (line.startswith("ZZZZ") and len(line) <= 12) or \
               (line.startswith("M") and ("/" in line or line[1:5].isdigit())) or \
               (line.startswith("K") and line[1:4].isdigit()):
                if not in_tag_block:
                    service_lines.append(line)
                else:
                    tag_block_parts.append(line)
            else:
                in_tag_block = True
                tag_block_parts.append(line)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        shr["start"] = service_lines[0][:8] if len(service_lines) > 0 else ""
        shr["higth"] = service_lines[1].split()[0] if len(service_lines) > 1 else ""
        shr["end"] = service_lines[2][:8] if len(service_lines) > 2 else ""

        # –°–æ–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —Ç–µ–≥–æ–≤
        main_block = " ".join(tag_block_parts)
        main_block = re.sub(r'\)\s*$', '', main_block).strip()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
        tags = ["DEP", "DEST", "DOF", "OPR", "REG", "TYP", "STS", "EET", "RMK", "SID"]
        for tag in tags:
            pattern = rf"{tag}/(.*?)(?=\s+[A-Z]{{3,}}/|$)"
            match = re.search(pattern, main_block, re.DOTALL)
            if match:
                value = match.group(1).strip()
                value = re.sub(r'\)\s*$', '', value)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
                if tag in ["DEP", "DEST"] and value:
                    if not is_valid_coords(value):
                        shr[f"{tag}_invalid"] = value
                        value = None
                
                shr[tag] = value if value else None
            else:
                shr[tag] = None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å—Ç—Ä–æ–∫
        for service_line in service_lines:
            if is_valid_coords(service_line):
                shr["service_line_coords"] = service_line

    except Exception as e:
        shr["error"] = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ SHR: {str(e)}"
    return shr

def dep_arr_pars(message):
    """–ü–∞—Ä—Å–∏–Ω–≥ DEP/ARR —Å–æ–æ–±—â–µ–Ω–∏–π"""
    res = {}
    if not message or len(str(message).strip()) == 0:
        return res
    try:
        lines = str(message).strip().splitlines()
        for line in lines:
            line = line.strip()
            if not line.startswith('-'):
                continue
            parts = line[1:].split(maxsplit=1)
            if len(parts) < 1:
                continue
            tag = parts[0]
            value = parts[1] if len(parts) > 1 else ""
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–ª—è ADEPZ –∏ ADARRZ
            if tag in ["ADEPZ", "ADARRZ"] and value:
                if not is_valid_coords(value):
                    res[f"{tag}_invalid"] = value
                    value = None
            
            res[tag] = value.strip()
    except Exception as e:
        res["error"] = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}"
    return res

# === üóÑ –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ë–î ===

class RegionFinder:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –∏—Å–ø–æ–ª—å–∑—É—è GeoJSON"""
    
    def __init__(self):
        self.geojson_file = find_geojson_file()
        self.gdf = None
        self.regions_map = {}
        
    def load_regions(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–≥–∏–æ–Ω—ã –∏–∑ GeoJSON —Ñ–∞–π–ª–∞"""
        if not self.geojson_file:
            logger.error("‚ùå GeoJSON —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        try:
            self.gdf = gpd.read_file(self.geojson_file)
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.gdf)} —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏–∑ GeoJSON: {os.path.basename(self.geojson_file)}")
            
            # –°–æ–∑–¥–∞–µ–º –∫—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            for idx, row in self.gdf.iterrows():
                region_id = idx + 1
                self.regions_map[region_id] = {
                    'name': row['region'],
                    'geometry': row['geometry']
                }
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ GeoJSON: {e}")
            return False
    
    def parse_compact_coords_to_decimal(self, coords_str):
        """–ü–∞—Ä—Å–∏—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞ 554531N0382513E –∏–ª–∏ 5957N02905E –≤ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –≥—Ä–∞–¥—É—Å—ã"""
        if not coords_str:
            return None, None
        
        try:
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
            coords_str = coords_str.replace(" ", "").upper()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø–æ –¥–ª–∏–Ω–µ —Å—Ç—Ä–æ–∫–∏
            if len(coords_str) == 11:
                # –§–æ—Ä–º–∞—Ç DDMMNDDDMME (–≥—Ä–∞–¥—É—Å—ã –∏ –º–∏–Ω—É—Ç—ã)
                lat_deg = int(coords_str[0:2])
                lat_min = int(coords_str[2:4])
                lat_dir = coords_str[4]
                lat_sec = 0
                
                lon_deg = int(coords_str[5:8])
                lon_min = int(coords_str[8:10])
                lon_dir = coords_str[10]
                lon_sec = 0
                
            elif len(coords_str) == 15:
                # –§–æ—Ä–º–∞—Ç DDMMSSNDDDMMSSE (–≥—Ä–∞–¥—É—Å—ã, –º–∏–Ω—É—Ç—ã –∏ —Å–µ–∫—É–Ω–¥—ã)
                lat_deg = int(coords_str[0:2])
                lat_min = int(coords_str[2:4])
                lat_sec = int(coords_str[4:6])
                lat_dir = coords_str[6]
                
                lon_deg = int(coords_str[7:10])
                lon_min = int(coords_str[10:12])
                lon_sec = int(coords_str[12:14])
                lon_dir = coords_str[14]
                
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {coords_str} (–¥–ª–∏–Ω–∞: {len(coords_str)})")
                return None, None

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –≥—Ä–∞–¥—É—Å—ã
            lat = lat_deg + lat_min / 60.0 + lat_sec / 3600.0
            if lat_dir == "S":
                lat = -lat

            lon = lon_deg + lon_min / 60.0 + lon_sec / 3600.0
            if lon_dir == "W":
                lon = -lon

            return lon, lat  # (lon, lat) –¥–ª—è GeoPandas
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç '{coords_str}': {e}")
            return None, None
    
    def find_region_by_coords(self, coords_str):
        """–ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–≥–∏–æ–Ω –ø–æ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –∏—Å–ø–æ–ª—å–∑—É—è GeoJSON"""
        if not coords_str:
            return None
        
        # –ü–∞—Ä—Å–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –≥—Ä–∞–¥—É—Å—ã
        lon, lat = self.parse_compact_coords_to_decimal(coords_str)
        if lon is None or lat is None:
            return None
        
        # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É
        point = Point(lon, lat)
        
        # –ò—â–µ–º —Ä–µ–≥–∏–æ–Ω, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–æ—á–∫—É
        for region_id, region_data in self.regions_map.items():
            try:
                if region_data['geometry'].contains(point):
                    logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ä–µ–≥–∏–æ–Ω {region_id} –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç {coords_str}")
                    return region_id
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–≥–∏–æ–Ω–∞ {region_data['name']}: {e}")
                continue
        
        logger.debug(f"‚ùå –†–µ–≥–∏–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç {coords_str}")
        return None

def recreate_table_if_schema_changed(engine):
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ —Å—Ö–µ–º–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å"""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = :table_name
            ORDER BY ordinal_position;
        """), {"table_name": TABLE_NAME})
        current_columns = {row[0]: row[1] for row in result}

        schema_changed = False
        for col, dtype in DESIRED_COLUMNS.items():
            base_type = dtype.split()[0].upper()
            if col not in current_columns or current_columns[col].upper() != base_type:
                schema_changed = True
                break

        if schema_changed:
            logger.info("üîÑ –°—Ö–µ–º–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å ‚Äî –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É...")
            conn.execute(text(f"DROP TABLE IF EXISTS {TABLE_NAME};"))
            
            columns_def = ",\n    ".join([f"{col} {dtype}" for col, dtype in DESIRED_COLUMNS.items()])
            create_sql = f"""
                CREATE TABLE {TABLE_NAME} (
                    {columns_def}
                );
            """
            conn.execute(text(create_sql))
            
            conn.execute(text(f"""
                CREATE INDEX idx_flights_region_id 
                ON {TABLE_NAME} (takeoff_region_id);
            """))
            
            conn.commit()
            logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ '{TABLE_NAME}' –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞.")
        else:
            logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ '{TABLE_NAME}' –∞–∫—Ç—É–∞–ª—å–Ω–∞.")

def parse_dof(dof_str):
    """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ YYMMDD"""
    if not dof_str or len(dof_str) != 6:
        return None
    try:
        year = 2000 + int(dof_str[:2])
        return f"{year}-{dof_str[2:4]}-{dof_str[4:6]}"
    except:
        return None

def extract_time_from_code(code):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Ä–µ–º—è –∏–∑ –∫–æ–¥–∞"""
    if not code:
        return None
    clean = ''.join(filter(str.isdigit, str(code)))
    if len(clean) >= 4:
        time_digits = clean[-4:]
        if time_digits.isdigit():
            hour, minute = time_digits[:2], time_digits[2:4]
            if hour.isdigit() and minute.isdigit():
                h, m = int(hour), int(minute)
                if 0 <= h <= 23 and 0 <= m <= 59:
                    return f"{hour}:{minute}"
    return None

def calculate_flight_duration(takeoff_time, landing_time, dof):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª–µ—Ç–∞ –≤ –º–∏–Ω—É—Ç–∞—Ö"""
    if not all([takeoff_time, landing_time, dof]):
        return None
    try:
        t_off = datetime.strptime(takeoff_time, "%H:%M")
        t_land = datetime.strptime(landing_time, "%H:%M")
        base_date = datetime.strptime(dof, "%Y-%m-%d")

        takeoff_dt = base_date.replace(hour=t_off.hour, minute=t_off.minute)
        landing_dt = base_date.replace(hour=t_land.hour, minute=t_land.minute)

        if landing_dt <= takeoff_dt:
            landing_dt += timedelta(days=1)

        duration = (landing_dt - takeoff_dt).total_seconds() / 60
        return int(round(duration))
    except:
        return None

def update_takeoff_regions_geojson(engine, region_finder):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ä–µ–≥–∏–æ–Ω—ã –≤—ã–ª–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è GeoJSON"""
    logger.info("üåç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤—ã–ª–µ—Ç–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º (GeoJSON)...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–≥–∏–æ–Ω—ã
    if not region_finder.load_regions():
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–≥–∏–æ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
        return
    
    with engine.connect() as conn:
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
        result = conn.execute(text(f"""
            SELECT id, takeoff_coords 
            FROM {TABLE_NAME} 
            WHERE takeoff_coords IS NOT NULL 
              AND takeoff_region_id IS NULL
            LIMIT 10000
        """))
        records = result.fetchall()

        if not records:
            logger.info("‚úÖ –í—Å–µ —Ä–µ–≥–∏–æ–Ω—ã —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∏–ª–∏ –Ω–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            return

        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(records)} –∑–∞–ø–∏—Å–µ–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        
        updated = 0
        errors = 0
        no_region_found = 0
        
        for row in records:
            flight_id, coords_str = row
            if not coords_str:
                continue

            try:
                # –ò—â–µ–º —Ä–µ–≥–∏–æ–Ω –∏—Å–ø–æ–ª—å–∑—É—è GeoJSON
                region_id = region_finder.find_region_by_coords(coords_str)
                
                if region_id is not None:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                    conn.execute(
                        text(f"""
                            UPDATE {TABLE_NAME} 
                            SET takeoff_region_id = :region_id
                            WHERE id = :id
                        """),
                        {
                            "region_id": region_id,
                            "id": flight_id
                        }
                    )
                    updated += 1
                else:
                    no_region_found += 1
                
                if (updated + no_region_found) % 100 == 0:
                    logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {updated + no_region_found} –∑–∞–ø–∏—Å–µ–π...")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø–∏—Å–∏ {flight_id}: {e}")
                errors += 1

        conn.commit()
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {updated} –∑–∞–ø–∏—Å–µ–π —Å —Ä–µ–≥–∏–æ–Ω–∞–º–∏ –≤—ã–ª–µ—Ç–∞.")
        logger.info(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–ª—è {no_region_found} –∑–∞–ø–∏—Å–µ–π.")
        if errors > 0:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {errors}")

def get_region_statistics(engine):
    """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º"""
    logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º:")
    
    try:
        with engine.connect() as conn:
            # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            result = conn.execute(text(f"SELECT COUNT(*) FROM {TABLE_NAME} WHERE takeoff_coords IS NOT NULL"))
            total_with_coords = result.scalar()
            logger.info(f"üìà –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: {total_with_coords}")
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ —Ä–µ–≥–∏–æ–Ω–∞–º–∏
            result = conn.execute(text(f"SELECT COUNT(*) FROM {TABLE_NAME} WHERE takeoff_region_id IS NOT NULL"))
            total_with_regions = result.scalar()
            logger.info(f"üìà –ó–∞–ø–∏—Å–µ–π —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ —Ä–µ–≥–∏–æ–Ω–∞–º–∏: {total_with_regions}")

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ä–µ–≥–∏–æ–Ω–æ–≤
            result = conn.execute(text(f"SELECT COUNT(*) FROM {TABLE_NAME} WHERE takeoff_coords IS NOT NULL AND takeoff_region_id IS NULL"))
            total_without_regions = result.scalar()
            logger.info(f"üìà –ó–∞–ø–∏—Å–µ–π –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: {total_without_regions}")

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–µ—Ç–æ–≤ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
            result = conn.execute(text(f"""
                SELECT r.region, COUNT(f.id) as flight_count
                FROM {REGIONS_TABLE} r
                LEFT JOIN {TABLE_NAME} f ON r.id = f.takeoff_region_id
                GROUP BY r.id, r.region
                HAVING COUNT(f.id) > 0
                ORDER BY flight_count DESC
                LIMIT 20;
            """))
            
            logger.info("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
            logger.info("‚îÇ –†–µ–≥–∏–æ–Ω                         ‚îÇ –ö–æ–ª-–≤–æ –ø–æ–ª—ë—Ç–æ–≤ ‚îÇ")
            logger.info("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
            
            has_data = False
            for row in result:
                region_name = row[0] if row[0] else "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
                count = row[1] if row[1] else 0
                region_display = region_name[:30] + "..." if len(region_name) > 30 else region_name
                logger.info(f"‚îÇ {region_display:<30} ‚îÇ {count:>12} ‚îÇ")
                has_data = True
            
            if not has_data:
                logger.info("‚îÇ          –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª—ë—Ç–∞—Ö           ‚îÇ")
            
            logger.info("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

def process_flight_data_excel(file_path, original_filename):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª–µ—Ç–∞—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞"""
    start_time = time.time()
    
    try:
        # === –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï –ö –ë–î ===
        try:
            engine = create_engine(DB_URL)
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å–ø–µ—à–Ω–æ.")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}"}

        # === –ü–û–î–ì–û–¢–û–í–ö–ê –¢–ê–ë–õ–ò–¶–´ ===
        recreate_table_if_schema_changed(engine)

        # === –ß–¢–ï–ù–ò–ï EXCEL –§–ê–ô–õ–ê ===
        try:
            df = pd.read_excel(file_path)
            logger.info(f"‚úÖ –§–∞–π–ª Excel –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel —Ñ–∞–π–ª–∞: {e}")
            return {"success": False, "error": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel —Ñ–∞–π–ª–∞: {e}"}

        # === –ù–ê–°–¢–†–û–ô–ö–ê –ü–ê–†–°–ï–†–û–í ===
        column_parsers = {}
        for col in df.columns:
            col_lower = col.strip().lower()
            if col_lower == "shr":
                column_parsers[col] = shr_pars
            elif col_lower in ("dep", "arr"):
                column_parsers[col] = dep_arr_pars
            else:
                logger.info(f"‚ö†Ô∏è  –°—Ç–æ–ª–±–µ—Ü '{col}' –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω, –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω.")

        # === –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –ò –ó–ê–ü–ò–°–¨ –í –ë–î ===
        inserted_records = 0
        stats = {
            "total_processed": 0,
            "valid_dep_coords": 0,
            "valid_dest_coords": 0,
            "corrected_coords": 0
        }

        logger.info(f"\nüîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(df)} –∑–∞–ø–∏—Å–µ–π...")

        with engine.connect() as conn:
            for idx, row in df.iterrows():


                stats["total_processed"] += 1
                
                if stats["total_processed"] % 1000 == 0:
                    logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {stats['total_processed']} –∑–∞–ø–∏—Å–µ–π...")

                # === –ü–ê–†–°–ò–ù–ì –î–ê–ù–ù–´–• ===
                parsed_data = {}
                for col_name, parser_func in column_parsers.items():
                    value = row[col_name]
                    parsed = parser_func(value)
                    parsed_data[col_name] = parsed

                # === –û–ë–†–ê–ë–û–¢–ö–ê –ö–û–û–†–î–ò–ù–ê–¢ –° –ü–†–ò–û–†–ò–¢–ï–¢–û–ú ===
                shr_data = parsed_data.get('SHR', {})
                dep_data = parsed_data.get('DEP', {})
                arr_data = parsed_data.get('ARR', {})
                
                # –ö–û–û–†–î–ò–ù–ê–¢–´ –í–´–õ–ï–¢–ê
                dep_coords = get_best_coords(
                    dep_data.get('ADEPZ'),
                    shr_data.get('DEP'),
                    shr_data.get('service_line_coords')
                )
                
                # –ö–û–û–†–î–ò–ù–ê–¢–´ –ü–û–°–ê–î–ö–ò
                dest_coords = get_best_coords(
                    arr_data.get('ADARRZ'),
                    shr_data.get('DEST')
                )
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                if dep_coords:
                    stats["valid_dep_coords"] += 1
                if dest_coords:
                    stats["valid_dest_coords"] += 1
                if (dep_coords and not shr_data.get('DEP')) or (dest_coords and not shr_data.get('DEST')):
                    stats["corrected_coords"] += 1

                # === –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ë–î ===
                flight_id = shr_data.get("flight_id") or None
                sid = shr_data.get("SID") or None
                
                if not (flight_id or sid):
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤

                dof = parse_dof(shr_data.get("DOF"))

                # –í—Ä–µ–º—è –≤—ã–ª–µ—Ç–∞
                takeoff_time = None
                if dep_data and dep_data.get("ATD"):
                    takeoff_time = extract_time_from_code(dep_data["ATD"])
                if not takeoff_time and shr_data.get("start"):
                    takeoff_time = extract_time_from_code(shr_data["start"])

                # –í—Ä–µ–º—è –ø–æ—Å–∞–¥–∫–∏
                landing_time = None
                if arr_data and arr_data.get("ATA"):
                    landing_time = extract_time_from_code(arr_data["ATA"])
                if not landing_time and shr_data.get("end"):
                    landing_time = extract_time_from_code(shr_data["end"])

                duration = calculate_flight_duration(takeoff_time, landing_time, dof)

                # === –ó–ê–ü–ò–°–¨ –í –ë–î ===
                try:
                    conn.execute(
                        text(f"""
                            INSERT INTO {TABLE_NAME} (
                                flight_id, dof, opr, reg, typ, typ_desc, sid, source_file,
                                takeoff_time, landing_time, takeoff_coords, landing_coords,
                                takeoff_region_id, flight_duration_minutes
                            ) VALUES (
                                :flight_id, :dof, :opr, :reg, :typ, :typ_desc, :sid, :source_file,
                                :takeoff_time, :landing_time, :takeoff_coords, :landing_coords,
                                NULL, :flight_duration_minutes
                            )
                        """),
                        {
                            "flight_id": flight_id,
                            "dof": dof,
                            "opr": shr_data.get("OPR") or None,
                            "reg": shr_data.get("REG") or None,
                            "typ": shr_data.get("TYP") or None,
                            "typ_desc": TYP_DESCRIPTIONS.get(shr_data.get("TYP"), shr_data.get("TYP")) if shr_data.get("TYP") else None,
                            "sid": sid,
                            "source_file": original_filename,
                            "takeoff_time": takeoff_time,
                            "landing_time": landing_time,
                            "takeoff_coords": dep_coords,  # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ takeoff_coords
                            "landing_coords": dest_coords, # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ landing_coords
                            "flight_duration_minutes": duration
                        }
                    )
                    inserted_records += 1
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –∑–∞–ø–∏—Å–∏ {idx}: {e}")
                    continue

            conn.commit()

        # === –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –†–ï–ì–ò–û–ù–û–í ===
        region_finder = RegionFinder()  # –¢–µ–ø–µ—Ä—å –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        update_takeoff_regions_geojson(engine, region_finder)

        # === –†–ê–°–ß–ï–¢ –ú–ï–¢–†–ò–ö ===
        logger.info("üìä –ó–∞–ø—É—Å–∫ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫...")
        metrics_result = calculate_metrics()
        if metrics_result["success"]:
            logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –¥–ª—è {metrics_result['regions_count']} —Ä–µ–≥–∏–æ–Ω–æ–≤")
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏: {metrics_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

        # === –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        end_time = time.time()
        elapsed = end_time - start_time
        
        logger.info(f"\n{'='*60}")
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        logger.info('='*60)
        logger.info(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {stats['total_processed']}")
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ –ë–î: {inserted_records}")
        logger.info(f"–ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—ã–ª–µ—Ç–∞: {stats['valid_dep_coords']}")
        logger.info(f"–ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ—Å–∞–¥–∫–∏: {stats['valid_dest_coords']}")
        logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {stats['corrected_coords']}")
        logger.info(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info('='*60)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
        get_region_statistics(engine)

        logger.info("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

        return {
            "success": True,
            "flights_count": inserted_records,
            "regions_count": stats.get("valid_dep_coords", 0),
            "database_updated": True,
            "metrics_calculated": metrics_result["success"],
            "statistics": stats,
            "summary": {
                "message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {inserted_records} –ø–æ–ª–µ—Ç–æ–≤",
                "processing_time": f"{elapsed:.2f} —Å–µ–∫—É–Ω–¥",
                "coordinates_stats": {
                    "valid_departure": stats["valid_dep_coords"],
                    "valid_destination": stats["valid_dest_coords"],
                    "corrected": stats["corrected_coords"]
                }
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª–µ—Ç–∞—Ö: {e}")
        return {
            "success": False,
            "error": str(e)
        }
    finally:
        # –§–∞–π–ª –ù–ï —É–¥–∞–ª—è–µ–º, —Ç–∞–∫ –∫–∞–∫ –æ–Ω —Ç–µ–ø–µ—Ä—å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π
        pass